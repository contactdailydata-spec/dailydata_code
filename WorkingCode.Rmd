---
title: "WorkingCode"
output: html_document
date: "2025-09-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
```{r}
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("dplyr")
library(ggplot2)
library(tidyr)
library(dplyr)

#install.packages("showtext")
library(showtext)

#install.packages("scales")
library(scales)
```


# Unemployment by age over years
## Read file
```{r}
Unemployment_Age_Year<-read.csv("Unemployment_Age_Year.csv")
```

## Clean dataset
```{r}
# Changing numbers from character with a % sign to numeric 
Unemployment_Age_Year$X20.24.Years <- as.numeric(gsub("%", "", Unemployment_Age_Year$X20.24.Years))
Unemployment_Age_Year$X25.34.Years <- as.numeric(gsub("%", "", Unemployment_Age_Year$X25.34.Years))
Unemployment_Age_Year$X35.44.Years <- as.numeric(gsub("%", "", Unemployment_Age_Year$X35.44.Years))
Unemployment_Age_Year$X45.54.Years <- as.numeric(gsub("%", "", Unemployment_Age_Year$X45.54.Years))
Unemployment_Age_Year$X55..Years <- as.numeric(gsub("%", "", Unemployment_Age_Year$X55..Years))

# changing column names so they are cleaner
colnames(Unemployment_Age_Year)<-c("Year","20-24","25-34","35-44","45-55","55+")

# Long format
Unemployment_Age_Year_long <- Unemployment_Age_Year %>%
  pivot_longer(cols = -Year, names_to = "AgeGroup", values_to = "Value")
```

## Graph
```{r}

font_add_google("Lato", "lato")  # load Lato font with alias "lato"
showtext_auto()                      # Enable showtext for future plots

myplot<-ggplot(Unemployment_Age_Year_long, aes(x = Year, y = Value, color = AgeGroup)) +
  geom_line(size = 1) +
  # Add vertical lines for 2008 and 2020
  geom_vline(xintercept = 2008, linetype = "dashed", color = "gray40", size = 0.8) +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "gray40", size = 0.8) +
  # Add text annotations for the events
  annotate("text", x = 2008, y = max(Unemployment_Age_Year_long$Value) * 0.95, 
           label = "2008 Recession", angle = 90, hjust = .75, vjust = -0.5, size = 4, color = "gray20") +
  annotate("text", x = 2020, y = max(Unemployment_Age_Year_long$Value) * 0.95, 
           label = "COVID-19", angle = 90, hjust=.5, vjust = -0.5, size = 4, color = "gray20") +
  labs(
    title ="",
    x = "Year",
    y = "Unemployment Rate (%)",
    color = "Age Group"
  ) +
  theme_classic(base_family = "lato") +  # use the Google font alias here
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 11),
    legend.position = "bottom"
  )+
    scale_color_manual(values = c(
    "20-24"  = "#264653",  # dark blue-green
    "25-34" = "#2a9d8f",  # medium teal
    "35-44" = "#e9c46a",  # warm yellow
    "45-55" = "#f4a261",  # soft orange
    "55+"   = "#e76f51"   # muted red-orange
  ))

```

# Approximate number of Refugees hosted by country as of end of 2024
```{r}
CountryRefugees<-read.csv("CountryRefugees.csv") # add data
colnames(CountryRefugees)<-c("Country", "Refugees") # change column names
CountryRefugees$Refugees <- as.numeric(gsub(",", "", CountiesRefugees$Refugees)) # remove comma and make numeric
CountryRefugees$Country <- factor(CountryRefugees$Country, levels = CountryRefugees$Country[order(CountryRefugees$Refugees)]) # put data in decending order

# make plot
myplot<-ggplot(CountryRefugees, aes(x = Country, y = Refugees, fill = Refugees)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = scales::comma(Refugees)), 
            hjust = -0.1, size = 3.5, color = "black") +
  coord_flip() +
  labs(title = NULL, x = "Host Country", y = "Number of Refugees") +
  theme_minimal(base_size = 14) +
  theme(
    axis.title = element_text(face = "bold"),
    axis.text.y = element_text(size = 12),
    axis.text.x = element_text(size = 10),
    plot.margin = margin(10, 20, 10, 10),
    legend.position = "none"  # hide legend if you want
  ) +
  scale_y_continuous(labels = scales::comma, expand = expansion(mult = c(0, 0.1))) +
  scale_fill_gradient(low = "#FFC107", high = "#D84315")  # warm yellow to deep red

```

# How world chess championship games have ended
```{r}

data <- data.frame(
  Result = rep(c("Checkmate", "Resignation", "Draw"), each = 2),
  Player = rep(c("Challenger", "Defender"), times = 3),
  Count = c(1, 1, 13, 18, 8, 10)
)

ggplot(data, aes(x = Result, y = Count, fill = Player)) +
  geom_bar(
    stat = "identity",
    position = position_dodge(width = 0.7),
    width = 0.6,   # thinner bars
    color = "grey30",
    size = 0.25
  ) +
  scale_fill_manual(
    values = c(
      "Challenger" = "#E69F00",  # orange
      "Defender"   = "#56B4E9"   # blue
    )
  ) +
  labs(
    title = "",
    x = "Result",
    y = "Number of Games",
    fill = "Player"
  ) +
  theme_minimal(base_size = 8) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 12),
    panel.grid.major.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_line(color = "grey85")
  )



plot_pie_edge_labels_pct <- function(df, title) {
  df <- df %>%
    arrange(desc(Result)) %>%
    mutate(
      fraction = Count / sum(Count),
      percent = paste0(round(fraction * 100), "%"),
      ymax = cumsum(fraction),
      ymin = c(0, head(ymax, n = -1)),
      label_position = (ymax + ymin) / 2
    )
  
  ggplot(df, aes(x = 1, y = fraction, fill = Result)) +
    geom_bar(stat = "identity", width = 1, color = "white", size = 0.8) +
    coord_polar(theta = "y") +
    geom_segment(aes(x = 1.5, xend = 1.7, y = label_position, yend = label_position),
                 color = "black", size = 0.6) +
    geom_text(aes(x = 2, y = label_position, label = percent),  # Show percentage labels
              hjust = 0, size = 4, fontface = "bold") +
    labs(title = title) +
    theme_void() +
    scale_fill_grey(start = 0.3, end = 0.8) +
    xlim(0.5, 2) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      legend.position = "bottom",
      legend.title = element_blank(),
      legend.text = element_text(size = 12)
    )
}


challenger_data <- filter(data, Player == "Challenger")
plot_pie_edge_labels_pct(challenger_data, "Challenger's Results")

defender_data <- filter(data, Player == "Defender")
plot_pie_edge_labels_pct(defender_data, "Defender's Results")


```




# Chess checkmate heatmap
```{r}
#install.packages("patchwork")
library(patchwork)
# -----------------------------
# Dataset 1: Number of Checkmate Possibilities
# -----------------------------
chess_data1 <- tribble(
  ~rank, ~a, ~b, ~c, ~d, ~e, ~f, ~g, ~h,
  8, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
  7, 10000, 20000, 20000, 20000, 20000, 20000, 20000, 10000,
  6, 10000, 20000, 30000, 30000, 30000, 30000, 20000, 10000,
  5, 8333, 16667, 25000, 33337, 33333, 25000, 16667, 8333,
  4, 8333, 16667, 25000, 33333, 33333, 25000, 16667, 8333,
  3, 6666, 13334, 20000, 20000, 20000, 20000, 13334, 6666,
  2, 6666, 13334, 13334, 13334, 13334, 13334, 13334, 6666,
  1, 6666, 6666, 6666, 6666, 6666, 6666, 6666, 6666
)

long_data1 <- chess_data1 %>%
  pivot_longer(cols = a:h, names_to = "file", values_to = "value") %>%
  mutate(file = factor(file, levels = c("a","b","c","d","e","f","g","h")))

p1<-ggplot(long_data1, aes(x = file, y = rank, fill = value)) +
  geom_tile(color = "grey30", size = 0.3) +
  scale_fill_gradient(low = "#fee5d9", high = "#de2d26", guide = "none") +
  scale_y_continuous(trans = "reverse", breaks = 1:8) +
  labs(title = "Heatmap of All Possible Checkmate Positions") +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9, face = "bold")
  )

# -----------------------------
# Dataset 2: Actual Most Common Checkmate Positions
# -----------------------------
chess_data2 <- tribble(
  ~rank, ~a, ~b, ~c, ~d, ~e, ~f, ~g, ~h,
  8, 1.6, 0.9, 1.2, 1.5, 3.7, 2.7, 6.2, 3.1,
  7, 0.8, 1.1, 1.2, 1.5, 1.8, 1.5, 2.3, 1.0,
  6, 0.6, 0.9, 1.2, 1.5, 1.8, 1.4, 2.0, 0.9,
  5, 0.5, 0.8, 1.2, 1.5, 1.7, 1.3, 1.9, 0.8,
  4, 0.5, 0.7, 1.1, 1.4, 1.5, 1.1, 1.4, 0.7,
  3, 0.5, 0.7, 1.1, 1.4, 1.5, 1.1, 1.4, 0.7,
  2, 0.6, 0.9, 1.2, 1.4, 1.5, 1.1, 1.4, 0.8,
  1, 1.4, 1.1, 1.6, 2.0, 3.6, 2.6, 5.7, 3.9
)

long_data2 <- chess_data2 %>%
  pivot_longer(cols = a:h, names_to = "file", values_to = "value") %>%
  mutate(file = factor(file, levels = c("a","b","c","d","e","f","g","h")))

p2<-ggplot(long_data2, aes(x = file, y = rank, fill = value)) +
  geom_tile(color = "grey30", size = 0.3) +
  scale_fill_gradient(low = "#fff7f3", high = "#de2d26", guide = "none") +
  scale_y_continuous(trans = "reverse", breaks = 1:8) +
  labs(title = "Heatmap of Actual Most Common Checkmate Positions") +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9, face = "bold")
  )

p1+p2
```


# Coffee trade across continents Sankey diagram
```{r}
# Load libraries
#install.packages("igraph")
library(igraph)
#install.packages("ggraph")
library(ggraph)
#install.packages("tidyverse")
library(tidyverse)

# Create the data frame using data from the UN Comtrade 2023
coffee <- tibble(
  exporter = c("Brazil", "Brazil", "Brazil", "Vietnam", "Vietnam",
               "Colombia", "Indonesia", "Honduras", "India", "Uganda", "Ethiopia"),
  importer = c("US", "Germany", "Italy", "US", "Japan",
               "US", "Japan", "US", "Germany", "Germany", "Germany"),
  value = c(1.47, 0.20, 0.10, 0.35, 0.43,
            0.77, 0.34, 0.44, 0.23, 0.26, 0.25) # example in million tonnes
)

coffee <- coffee %>%
  mutate(value_mkg = value * 1000)  # million tonnes â†’ million kg

# Load ggalluvial (assuming package installed)
#install.packages("ggalluvial")
library(ggalluvial)
library(ggplot2)

# Define a color palette for the exporters
exporter_colors <- c(
  "Brazil"    = "#A8D0E6",  # soft sky blue
  "Vietnam"   = "#F6C1B9",  # pastel peach
  "Colombia"  = "#F6EAC2",  # light cream
  "Indonesia" = "#C1E1C1",  # soft mint green
  "Honduras"  = "#FFD6A5",  # pastel apricot
  "India"     = "#E2C0FF",  # lavender
  "Uganda"    = "#FFB7B2",  # soft pink
  "Ethiopia"  = "#B5EAEA"   # pale turquoise
)

# Title of graph will be Global Coffee Trade Flows (Top Exporters â†’ Key Importers, 2023)
ggplot(coffee,
       aes(axis1 = exporter, axis2 = importer, y = value_mkg)) +
  geom_alluvium(aes(fill = exporter), width = 1/12, alpha = 0.5, show.legend = FALSE) +
  geom_stratum(width = 1/12, fill = gray(0.99), color = gray(0.90)) +

  # Stratum labels
  geom_text(stat = "stratum", aes(
    label = after_stat(stratum),
    hjust = after_stat(ifelse(x == 1, 1, 0)),
    x = after_stat(ifelse(x == 1, x - 0.05, x + 0.05))  # reduced nudging
  ),
  size = 3.5, fontface = "bold", color = "black") +

  # Flow numbers (midpoints of alluvia)
  geom_text(aes(label = value_mkg), stat = "alluvium",
            size = 3, color = "black")+
  scale_fill_manual(values = exporter_colors) +
  scale_x_discrete(
    limits = c("Exporter", "Importer"),
    expand = expansion(mult = c(0.2, 0.2))
  ) +
  labs(
    title = "",
    y = "Million Kilograms of Coffee Beans",
    x = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.ticks = element_blank(),
    axis.text.y = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```





# Air quality Events (API above moderate) in counties in  CONUS over the past few years
```{r}
#Data from EPA: https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI
# -------------------------------
# Load libraries (only once)
# -------------------------------
library(dplyr)
library(readr)
library(sf)
library(tigris)
library(ggplot2)
library(lubridate)
library(patchwork)

options(tigris_use_cache = TRUE)

# -------------------------------
# Load CONUS county geometries
# -------------------------------
counties <- counties(cb = TRUE, year = 2022) %>%
  st_as_sf() %>%
  filter(!STATEFP %in% c("02","15","60","66","69","72","78"))  # Remove AK, HI, territories

# Load CONUS state boundaries
states_sf <- states(cb = TRUE, year = 2022) %>%
  st_as_sf() %>%
  filter(!STATEFP %in% c("02","15","60","66","69","72","78"))

# -------------------------------
# Compute global maximum for color scale
# -------------------------------
all_years <- 2019:2024
max_unhealthy <- 0

for (yr in all_years) {
  df_tmp <- read_csv(paste0("daily_aqi_by_county_", yr, ".csv"))
  tmp_count <- df_tmp %>%
    filter(Category %in% c("Unhealthy", 
                           "Very Unhealthy", 
                           "Hazardous")) %>%
    group_by(`State Code`, `County Code`) %>%
    summarise(n = n(), .groups = "drop")
  max_unhealthy <- max(max_unhealthy, max(tmp_count$n, na.rm = TRUE))
}

# -------------------------------
# Function to plot AQI exceedances
# -------------------------------
plot_aqi_exceedances <- function(df, year) {
  
  exceedance_levels <- c("Unhealthy", 
                         "Very Unhealthy", 
                         "Hazardous")
  
  df_year <- df %>%
    filter(year(Date) == year)
  
  unhealthy_days <- df_year %>%
    filter(Category %in% exceedance_levels) %>%
    group_by(`State Code`, `County Code`, `State Name`, `county Name`) %>%
    summarise(unhealthy_days = n(), .groups = "drop") %>%
    mutate(FIPS = sprintf("%02s%03s", `State Code`, `County Code`))
  
  map_data <- counties %>%
    left_join(unhealthy_days, by = c("GEOID" = "FIPS"))
  
  ggplot() +
    geom_sf(data = map_data, aes(fill = unhealthy_days), color = NA) +
    geom_sf(data = states_sf, fill = NA, color = "black", size = 0.3) +
    scale_fill_gradient(
      low = "lightpink",
      high = "darkred",
      limits = c(0, max_unhealthy),
      na.value = "grey90"
    ) +
    labs(
      title = as.character(year),
      fill = "Number of Unhealthy Air Quality Days"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16),
      axis.title = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank()
    )
}

# -------------------------------
# Generate plots for each year
# -------------------------------
p2024 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2024.csv"), 2024) & theme(legend.position = "none")
p2023 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2023.csv"), 2023) & theme(legend.position = "none")
p2022 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2022.csv"), 2022) & theme(legend.position = "none")
p2021 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2021.csv"), 2021) & theme(legend.position = "none")
p2020 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2020.csv"), 2020) & theme(legend.position = "none")
p2019 <- plot_aqi_exceedances(read_csv("daily_aqi_by_county_2019.csv"), 2019) & theme(legend.position = "none")

# -------------------------------
# Combine plots in 2x3 grid with one shared legend
# -------------------------------
combined <- (p2024 | p2023 | p2022) / 
            (p2021 | p2020 | p2019) + 
            plot_layout(guides = "collect") & theme(legend.position = "bottom")

# Display combined figure
combined

# Number of Wild fires according to national interagency fire center https://www.nifc.gov/fire-information/statistics/wildfires?utm_source=chatgpt.com

# 2019: 50,477
# 2020: 58,950
# 2021: 58,985
# 2022: 68,988
# 2023: 56,580
# 2024: 64,897

```



# Number and acres of wildfires each year in CA
```{r}
# DATA from: National Interagency Fire Center and CAL Fire
# Title: Acres of Wildfire Burn and Total Annual Precipitation in California from 2019-2024

library(ggplot2)

# Data
ca_fire_data <- data.frame(
  Year = 2019:2024,
  Precipitation = c(14.9, 5.8, 5.8, 28.4, 44.1, 25.2),
  Acres_Burned = c(4664364, 10122336, 7125643, 7577183, 2693910, 8924884)
)

# Scale factor for precipitation
max_acres <- max(ca_fire_data$Acres_Burned / 1e6)
max_precip <- max(ca_fire_data$Precipitation)
scale_factor <- max_acres / max_precip

# Plot
ggplot(ca_fire_data, aes(x = Year)) +
  
  # Bar for acres burned (in millions)
  geom_col(aes(y = Acres_Burned / 1e6), fill = "firebrick", alpha = 0.7) +
  
  # Line for precipitation, scaled
  geom_line(aes(y = Precipitation * scale_factor), color = "blue", size = 1.5) +
  geom_point(aes(y = Precipitation * scale_factor), color = "blue", size = 3) +
  
  # Y-axis labels
  scale_y_continuous(
    name = "Acres Burned (millions)",
    limits = c(0, 12),
    sec.axis = sec_axis(~ . / scale_factor, name = "Precipitation (inches)")
  ) +
  
  # X-axis breaks for each year
  scale_x_continuous(breaks = 2019:2024) +
  
  labs(
    title = "",
    x = "Year"
  ) +
  
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title.y.left = element_text(color = "firebrick", size = 14),
    axis.title.y.right = element_text(color = "blue", size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )


```



# Bad air quality and asthma deaths in California
```{r}
library(dplyr)
library(readr)
library(purrr)
library(stringr)

# Asthma data from California Department of public health https://data.chhs.ca.gov/dataset/asthma-hospitalization-rates-by-county
setwd("C:/Users/Alisha Yee Chan/Documents/Data/")
RawAsthmaData_County<-read.csv("asthma-hospitalization-rates-by-county-2015-Oct2024.csv")
AsthmaData_County_2015_2023<-filter(filter(RawAsthmaData_County, YEAR !=2024), COUNTY!="California")[,c(1,2,6)] # Only keep what's neccesary and Data in 2024 isn't complete so removing that year and removing California's total row
names(AsthmaData_County_2015_2023)[1]<-"County" # Rename column name COUNTY to lower case County
names(AsthmaData_County_2015_2023)[2]<-"Year"

# Air Quality events data from US EPA: https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI
# Directory where your CSV files are stored
path <- "C:/Users/Alisha Yee Chan/Documents/Data/"

# List all files matching the correct pattern
files <- list.files(path, pattern = "^annual_aqi_by_county_\\d{4}\\.csv$", full.names = TRUE)

# Load and combine all files into one dataframe
aqi_all <- files %>%
  map_dfr(~ read_csv(.x) %>%
            mutate(Year = str_extract(basename(.x), "\\d{4}")))

Cali_aqi_2015_2023<-data.frame(filter(aqi_all, State=="California"))
Cali_aqi_2015_2023$BadAQIDays<-Cali_aqi_2015_2023$Unhealthy.for.Sensitive.Groups.Days+Cali_aqi_2015_2023$Unhealthy.Days+Cali_aqi_2015_2023$Very.Unhealthy.Days+Cali_aqi_2015_2023$Hazardous.Days

# Income data
# Data from HDPulse: An Ecosystem of Minority Health and Health Disparities Resources. National Institute on Minority Health and Health Disparities. Created 9/16/2025. Available from https://hdpulse.nimhd.nih.gov


# California median household income and population count in 2023
ca_income_population_2023 <- data.frame(
  County = c("Trinity","Siskiyou","Imperial","Modoc",
             "Lake","Sierra","Humboldt","Tehama",
             "Lassen","Mendocino","Plumas","Merced",
             "Mariposa","Del Norte","Kern","Butte",
             "Kings","Tulare","Glenn","Fresno",
             "Shasta","Tuolumne","Inyo","Yuba",
             "Colusa","Sutter","Madera","Stanislaus",
             "Calaveras","Amador","San Bernardino","Nevada",
             "Mono","Los Angeles","San Joaquin","Sacramento",
             "Yolo","Riverside","San Luis Obispo","Monterey",
             "Santa Barbara","Solano","San Diego","Sonoma",
             "El Dorado","Ventura","San Benito","Napa",
             "Santa Cruz","Alpine","Orange","Placer",
             "Contra Costa","Alameda","San Francisco","Marin",
             "San Mateo","Santa Clara"),
  Median_Household_Income = c(53498,55499,56393,56648,58738,60000,61135,61834,
                              64395,64688,64946,65044,65378,66780,67660,68574,
                              68750,69489,70487,71434,71931,72259,72432,73313,
                              75149,75450,75496,79661,79877,81526,82184,84905,
                              86953,87760,88531,88724,88818,89672,93398,94486,
                              95977,99994,102285,102840,106190,107327,108289,108970,
                              109266,110781,113702,114678,125727,126240,141446,142785,
                              156000,159674),
  Population_count = c(13000,43000,181000,9000,67764,3000,135000,65000,
                       34000,87000,19000,300000,18000,28000,922529,228000,
                       152000,470000,29000,1024125,180000,55259,19000,80000,
                       22000,100000,165000,560000,46000,39000,2214281,100000,
                       15000,9663345,779233,1611231,230000,2529933,285000,435000,
                       448000,453000,3298799,510000,200000,835427,70000,140000,
                       275000,15000,3170435,400000,1172607,1649060,842000,270000,
                       774000,1877592)
)
library(dplyr)
library(ggplot2)
library(viridis)
library(scales)

# Step 1: Merge the asthma and AQI data
df <- AsthmaData_County_2015_2023 %>%
  inner_join(Cali_aqi_2015_2023, by = c("County", "Year")) %>%
  # Add Median Household Income + Population Count from 2023
  left_join(ca_income_population_2023, by = "County")

# Step 2: Fit Poisson model with population offset
poisson_model <- glm(NUMBER.OF.HOSPITALIZATIONS ~ BadAQIDays + Median_Household_Income +
                       offset(log(Population_count)),
                     data = df,
                     family = poisson())
summary(poisson_model)

# Step 3: Generate predictions for plotting
income_levels <- c(60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000)

pred_df <- expand.grid(
  BadAQIDays = seq(min(df$BadAQIDays), max(df$BadAQIDays), length.out = 100),
  Median_Household_Income = income_levels
)

# Use the average population so predictions are in total hospitalizations
avg_pop <- mean(df$Population_count)
pred_df$Population_count <- avg_pop

# Predict total hospitalizations with standard errors
pred <- predict(poisson_model, newdata = pred_df, type = "link", se.fit = TRUE)

# Calculate 95% confidence intervals on response scale
pred_df$Predicted_Hosp <- exp(pred$fit)
pred_df$CI_lower <- exp(pred$fit - 1.96 * pred$se.fit)
pred_df$CI_upper <- exp(pred$fit + 1.96 * pred$se.fit)

# Keep Income_Label numeric for plotting, ordered high â†’ low
pred_df$Income_Label <- factor(pred_df$Median_Household_Income,
                               levels = rev(income_levels))

# Create formatted labels for legend
income_labels <- setNames(dollar(income_levels), income_levels)

# Step 4: Plot predicted total hospitalizations with shaded confidence intervals
ggplot(pred_df, aes(x = BadAQIDays, y = Predicted_Hosp, color = Income_Label, fill = Income_Label)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper), alpha = 0.2, color = NA) +
  labs(x = "Number of Unhealthy Air Quality Days in California",
       y = "Predicted Number of Asthma Hospitalizations in California",
       color = "Median Household Income",
       fill = "Median Household Income") +
  scale_color_viridis_d(option = "F", labels = income_labels) +
  scale_fill_viridis_d(option = "F", labels = income_labels) +
  theme_minimal()


```









